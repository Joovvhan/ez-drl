#!/usr/bin/env python3
"""ê³µí†µ í•™ìŠµ ì§„ì…ì 

ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ê³¼ í™˜ê²½ì— ëŒ€í•œ í†µí•© í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆì‹œ:
    # ê¸°ë³¸ ì‹¤í–‰ (ëŒ€í™”í˜• ëª¨ë“œ)
    python train.py

    # ëª…ë ¹ì¤„ ì¸ìë¡œ ì‹¤í–‰
    python train.py --env CartPole-v1 --algo ppo --timesteps 100000

    # ë³‘ë ¬ í™˜ê²½ ì‚¬ìš©
    python train.py --env CartPole-v1 --algo ppo --n-envs 4

    # ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° ì»¤ìŠ¤í„°ë§ˆì´ì§•
    python train.py --env CartPole-v1 --algo ppo --net-arch 256 256

    # ì‹œë“œ ê³ ì •
    python train.py --env CartPole-v1 --algo ppo --seed 42
"""
import argparse
import sys
from config import TrainingConfig, ENVIRONMENT_CONFIGS
from utils import train_model, test_model, print_available_configs


def parse_args():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description="ez-drl í†µí•© í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python train.py --env CartPole-v1 --algo ppo
  python train.py --env LunarLander-v3 --algo dqn --timesteps 500000
  python train.py --env BipedalWalker-v3 --algo sac --n-envs 4
  python train.py --list  # ì‚¬ìš© ê°€ëŠ¥í•œ í™˜ê²½ ëª©ë¡ ë³´ê¸°
        """
    )

    # ê¸°ë³¸ ì¸ì
    parser.add_argument(
        "--env",
        type=str,
        help="í™˜ê²½ ì´ë¦„ (ì˜ˆ: CartPole-v1, LunarLander-v3)"
    )
    parser.add_argument(
        "--algo",
        type=str,
        choices=["dqn", "a2c", "ppo", "sac"],
        help="ì•Œê³ ë¦¬ì¦˜ (dqn, a2c, ppo, sac)"
    )

    # í•™ìŠµ ì„¤ì •
    parser.add_argument(
        "--timesteps",
        type=int,
        help="ì´ í•™ìŠµ timesteps (ê¸°ë³¸ê°’: í™˜ê²½ë³„ ìë™ ì„¤ì •)"
    )
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=3e-4,
        help="í•™ìŠµë¥  (ê¸°ë³¸ê°’: 3e-4)"
    )
    parser.add_argument(
        "--n-envs",
        type=int,
        default=1,
        help="ë³‘ë ¬ í™˜ê²½ ìˆ˜ (ê¸°ë³¸ê°’: 1, A2C/PPOë§Œ ì§€ì›)"
    )

    # ë„¤íŠ¸ì›Œí¬ ì„¤ì •
    parser.add_argument(
        "--net-arch",
        type=int,
        nargs="+",
        help="ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° (ì˜ˆ: --net-arch 256 256)"
    )

    # ë¡œê¹… ë° ì €ì¥
    parser.add_argument(
        "--save-dir",
        type=str,
        default="results",
        help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: results)"
    )
    parser.add_argument(
        "--no-tensorboard",
        action="store_true",
        help="TensorBoard ë¡œê¹… ë¹„í™œì„±í™”"
    )
    parser.add_argument(
        "--log-interval",
        type=int,
        default=10,
        help="ë¡œê·¸ ì¶œë ¥ ê°„ê²© (ê¸°ë³¸ê°’: 10)"
    )

    # í‰ê°€
    parser.add_argument(
        "--eval-episodes",
        type=int,
        default=10,
        help="í‰ê°€ ì—í”¼ì†Œë“œ ìˆ˜ (ê¸°ë³¸ê°’: 10)"
    )

    # ì‹œë“œ
    parser.add_argument(
        "--seed",
        type=int,
        help="ëœë¤ ì‹œë“œ"
    )

    # ìœ í‹¸ë¦¬í‹°
    parser.add_argument(
        "--list",
        action="store_true",
        help="ì‚¬ìš© ê°€ëŠ¥í•œ í™˜ê²½ ë° ì•Œê³ ë¦¬ì¦˜ ëª©ë¡ ì¶œë ¥"
    )
    parser.add_argument(
        "--test",
        action="store_true",
        help="í•™ìŠµ í›„ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ë Œë”ë§)"
    )
    parser.add_argument(
        "--render",
        action="store_true",
        help="í•™ìŠµ ì¤‘ í™˜ê²½ì„ í™”ë©´ì— ë Œë”ë§ (ì‹œê°í™”)"
    )

    # ê³ ê¸‰ ì˜µì…˜
    parser.add_argument(
        "--policy",
        type=str,
        default="MlpPolicy",
        choices=["MlpPolicy", "CnnPolicy"],
        help="ì •ì±… íƒ€ì… (ê¸°ë³¸ê°’: MlpPolicy)"
    )

    return parser.parse_args()


def interactive_mode():
    """ëŒ€í™”í˜• ëª¨ë“œë¡œ ì„¤ì • ì…ë ¥"""
    print("\n" + "=" * 70)
    print("ğŸ® ez-drl ëŒ€í™”í˜• í•™ìŠµ ëª¨ë“œ")
    print("=" * 70)

    # í™˜ê²½ ì„ íƒ
    print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í™˜ê²½:")
    envs = list(ENVIRONMENT_CONFIGS.keys())
    for i, env in enumerate(envs, 1):
        env_config = ENVIRONMENT_CONFIGS[env]
        print(f"  {i}. {env}")
        print(f"     - Action: {env_config['action_space']}, State: {env_config['state_space']}")
        print(f"     - Algorithms: {', '.join(env_config['supported_algos'])}")

    while True:
        try:
            env_idx = int(input(f"\ní™˜ê²½ ì„ íƒ (1-{len(envs)}): ")) - 1
            if 0 <= env_idx < len(envs):
                env_name = envs[env_idx]
                break
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except (ValueError, KeyboardInterrupt):
            print("\n\nâš ï¸  ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            sys.exit(0)

    # ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
    supported_algos = ENVIRONMENT_CONFIGS[env_name]["supported_algos"]
    print(f"\nğŸ¤– {env_name}ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì•Œê³ ë¦¬ì¦˜:")
    for i, algo in enumerate(supported_algos, 1):
        print(f"  {i}. {algo.upper()}")

    while True:
        try:
            algo_idx = int(input(f"\nì•Œê³ ë¦¬ì¦˜ ì„ íƒ (1-{len(supported_algos)}): ")) - 1
            if 0 <= algo_idx < len(supported_algos):
                algorithm = supported_algos[algo_idx]
                break
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except (ValueError, KeyboardInterrupt):
            print("\n\nâš ï¸  ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            sys.exit(0)

    # ì¶”ê°€ ì„¤ì •
    print("\nâš™ï¸  ì¶”ê°€ ì„¤ì • (Enterë¥¼ ëˆ„ë¥´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©):")

    # Timesteps
    default_timesteps = TrainingConfig(env_name=env_name)._get_default_timesteps()
    timesteps_input = input(f"  ì´ timesteps (ê¸°ë³¸ê°’: {default_timesteps:,}): ").strip()
    total_timesteps = int(timesteps_input) if timesteps_input else default_timesteps

    # ë³‘ë ¬ í™˜ê²½
    if algorithm in ["a2c", "ppo"]:
        n_envs_input = input("  ë³‘ë ¬ í™˜ê²½ ìˆ˜ (ê¸°ë³¸ê°’: 1): ").strip()
        n_envs = int(n_envs_input) if n_envs_input else 1
    else:
        n_envs = 1

    # ì‹œë“œ
    seed_input = input("  ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: None): ").strip()
    seed = int(seed_input) if seed_input else None

    print("\n" + "=" * 70)

    # ì„¤ì • ìƒì„±
    config = TrainingConfig(
        env_name=env_name,
        algorithm=algorithm,
        total_timesteps=total_timesteps,
        n_envs=n_envs,
        seed=seed,
    )

    return config


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()

    # ëª©ë¡ ì¶œë ¥ ëª¨ë“œ
    if args.list:
        print_available_configs()
        return

    # ëŒ€í™”í˜• ëª¨ë“œ ë˜ëŠ” ëª…ë ¹ì¤„ ëª¨ë“œ
    if args.env is None or args.algo is None:
        # ì¸ìê°€ ì—†ìœ¼ë©´ ëŒ€í™”í˜• ëª¨ë“œ
        config = interactive_mode()
    else:
        # ë Œë”ë§ê³¼ ë³‘ë ¬ í™˜ê²½ ì¶©ëŒ ì²´í¬
        n_envs = args.n_envs
        render = args.render
        if args.render and args.n_envs > 1:
            print("\nâš ï¸  ê²½ê³ : ë³‘ë ¬ í™˜ê²½ì—ì„œëŠ” ë Œë”ë§ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print("   ë Œë”ë§ì„ í™œì„±í™”í•˜ë ¤ë©´ --n-envsë¥¼ 1ë¡œ ì„¤ì •í•˜ê±°ë‚˜,")
            print("   ë³‘ë ¬ í™˜ê²½ì„ ì‚¬ìš©í•˜ë ¤ë©´ --renderë¥¼ ì œê±°í•˜ì„¸ìš”.")
            user_choice = input("\nì„ íƒ: (1) ë Œë”ë§ ë¹„í™œì„±í™” (2) n-envs=1ë¡œ ë³€ê²½ (3) ì·¨ì†Œ [1/2/3]: ").strip()
            if user_choice == "2":
                n_envs = 1
                print("âœ“ n-envsë¥¼ 1ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\n")
            elif user_choice == "3":
                print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                sys.exit(0)
            else:
                render = False
                print("âœ“ ë Œë”ë§ì„ ë¹„í™œì„±í™”í–ˆìŠµë‹ˆë‹¤.\n")

        # ëª…ë ¹ì¤„ ì¸ìë¡œ ì„¤ì • ìƒì„±
        config = TrainingConfig(
            env_name=args.env,
            algorithm=args.algo,
            total_timesteps=args.timesteps if args.timesteps else 50000,
            learning_rate=args.learning_rate,
            n_envs=n_envs,
            net_arch=args.net_arch,
            save_dir=args.save_dir,
            tensorboard_log=not args.no_tensorboard,
            log_interval=args.log_interval,
            eval_episodes=args.eval_episodes,
            seed=args.seed,
            policy_type=args.policy,
            render=render,
            render_mode="human" if render else None,
        )

    # í•™ìŠµ ì‹¤í–‰
    try:
        model, mean_reward, std_reward = train_model(config)

        print("\n" + "=" * 70)
        print("âœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœì¢… í‰ê·  ë³´ìƒ: {mean_reward:.2f} Â± {std_reward:.2f}")
        print("=" * 70)

        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        if args.test:
            print("\nğŸ® í•™ìŠµëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...")
            test_model(config, n_episodes=3)

        # TensorBoard ì•ˆë‚´
        if config.tensorboard_log:
            print(f"\nğŸ’¡ TensorBoardë¡œ í•™ìŠµ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”:")
            print(f"   tensorboard --logdir {config.tb_log_dir}")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  í•™ìŠµì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
